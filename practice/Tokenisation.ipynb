{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9a23a3a8-b2bb-41d7-9214-e2a7eb08ec8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sarva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f8032297-d4c6-4a49-b42a-01bb5b9386e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Hi I am Sarvadnya.\n",
    "How are you?I am fine!This is Sarvadnya's workshop.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "73f50889-57d8-41e8-960f-a11f49565709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi I am Sarvadnya.\n",
      "How are you?I am fine!This is Sarvadnya's workshop.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f810a596-3074-4a84-a5a4-3827d1ef9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "#para -> sentence\n",
    "#sent_tokenize means sentence tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f409955e-fe7f-49d6-8a67-af88ec146b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2ea19df4-68e8-4e1e-8f2c-503f69776b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2d038b87-2a9d-4418-a778-c7a687e91653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi I am Sarvadnya.', \"How are you?I am fine!This is Sarvadnya's workshop.\"]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a0e564cb-3eb0-47e2-91b1-4f9330e4afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi I am Sarvadnya.\n",
      "How are you?I am fine!This is Sarvadnya's workshop.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)\n",
    "#if u put 4 !!!! then it will print 3!!! on 1 line and 1!on the next i.e. it will always print 1! on the next line if more than 1 ! are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6489e4bc-f56d-4da8-8443-c059a8a3fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization \n",
    "#para->words\n",
    "#sentence->words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "122e0bbc-30c2-4e47-9f3b-f7acf81bb25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Sarvadnya',\n",
       " '.',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'I',\n",
       " 'am',\n",
       " 'fine',\n",
       " '!',\n",
       " 'This',\n",
       " 'is',\n",
       " 'Sarvadnya',\n",
       " \"'s\",\n",
       " 'workshop',\n",
       " '.']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para->words\n",
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3dedae7c-240d-4dd9-820e-1ef78c87efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'I', 'am', 'Sarvadnya', '.']\n",
      "['How', 'are', 'you', '?', 'I', 'am', 'fine', '!', 'This', 'is', 'Sarvadnya', \"'s\", 'workshop', '.']\n"
     ]
    }
   ],
   "source": [
    "# sentence ->words\n",
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6c744798-067e-412b-aee6-4b76b5321df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to treat punctuation as a different word we use punct\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "db384b17-0810-48fe-9ac2-5aeda4c47519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Sarvadnya',\n",
       " '.',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'I',\n",
       " 'am',\n",
       " 'fine',\n",
       " '!',\n",
       " 'This',\n",
       " 'is',\n",
       " 'Sarvadnya',\n",
       " \"'\",\n",
       " 's',\n",
       " 'workshop',\n",
       " '.']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5d132dd9-6880-4870-a308-292b27a2214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding the last fullstop, other fullstops are not treated as a seperate word\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b850b9d6-068e-4f4d-a03e-86b598aca0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "94a3d6ca-00f3-483a-86fc-2da02c972a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Sarvadnya.',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'I',\n",
       " 'am',\n",
       " 'fine',\n",
       " '!',\n",
       " 'This',\n",
       " 'is',\n",
       " 'Sarvadnya',\n",
       " \"'s\",\n",
       " 'workshop',\n",
       " '.']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f9714ff8-9afe-43f1-b4c9-340da79d5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUTORIAL 2\n",
    "# Stemming ->finding the stem word eg eating,eats,eaten all have tha same stem word ie eat\n",
    "words = [\"eating\",\"eating\",\"EaTs\",\"wriTing\",\"WRITES\",\"programing\",\"programs \",\"history\",\"finally\",\"finals\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a36dd2c4-c848-4f76-a4ba-b45ab0f562fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###porter stemmer\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "898f9ff7-a124-477a-84a8-10ca0be87191",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ea7fe1a1-476c-4f3d-9975-66d6917e730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eating--->eat\n",
      "EaTs--->eat\n",
      "wriTing--->write\n",
      "WRITES--->write\n",
      "programing--->program\n",
      "programs --->programs \n",
      "history--->histori\n",
      "finally--->final\n",
      "finals--->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "37acc89e-24a7-4044-9e38-87f7980603bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###RegexpStemmer(regular expression stemmer class)\n",
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "51a6cd18-26df-442b-a563-3e12cfc2af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$',min =4)\n",
    "#removes the given words from the last if $ sign of ing is removed then all the presences of the ing will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7a8bc04f-faba-440e-9cec-24d401f4b87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "fae88603-8775-4fe4-94df-f05137a1769a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "70cb7574-c831-483a-af9f-558ca5d54f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "###SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "589ab0fb-5ffe-40fc-9017-a69302564953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "fdd0622c-9542-48a5-a840-d96dcbba6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fb764d89-7fe9-4998-b14f-9ce891bf9df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eat\n",
      "eating-->eat\n",
      "EaTs-->eat\n",
      "wriTing-->write\n",
      "WRITES-->write\n",
      "programing-->program\n",
      "programs -->programs \n",
      "history-->histori\n",
      "finally-->final\n",
      "finals-->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-->\"+snowballstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "043916c5-a55c-4465-a16d-a9d9418453eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('fairly'),stemming.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9a45a34e-91a9-4cb7-996e-5eb5f0111881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem('fairly'),snowballstemmer.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959c269-27dd-4374-a179-168b1de6d441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
